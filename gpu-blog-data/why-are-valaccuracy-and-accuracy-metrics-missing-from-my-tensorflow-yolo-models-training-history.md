---
title: "Why are 'val_accuracy' and 'accuracy' metrics missing from my TensorFlow YOLO model's training history?"
date: "2025-01-26"
id: "why-are-valaccuracy-and-accuracy-metrics-missing-from-my-tensorflow-yolo-models-training-history"
---

The absence of 'val_accuracy' and 'accuracy' metrics in a TensorFlow YOLO model's training history stems from the fundamental nature of the YOLO architecture, and its common usage in object detection tasks rather than classification. I've encountered this precise issue multiple times during my experience developing custom object detection pipelines and troubleshooting model training. YOLO, or You Only Look Once, isn't designed to classify individual images into distinct categories; instead, it aims to simultaneously localize and classify multiple objects within a single image. This core difference dictates the metrics used to evaluate its performance.

Unlike traditional image classification models, which output a single probability distribution across classes, a YOLO model produces bounding box coordinates, object confidence scores, and class probabilities for each detected object. The model is not inherently concerned with predicting the *overall* class of the input image; its focus lies on correctly identifying and positioning objects *within* the image. Therefore, standard classification metrics like 'accuracy' (the proportion of correctly classified images) and its validation counterpart, 'val_accuracy', are inapplicable in this context. They do not directly translate to the multi-faceted outputs generated by YOLO. Instead, performance is judged using more suitable measures.

Commonly employed metrics for evaluating YOLO performance include mean average precision (mAP), precision, recall, and F1-score. These metrics operate at the level of object detections rather than image classifications, assessing how well the model is able to both locate objects and accurately categorize them. They evaluate the agreement between predicted bounding boxes and ground-truth annotations, and assess class-specific classification performance within these detections.

Let's consider how these metrics come into play. When training a YOLO model, the loss function typically involves several components including localization loss, confidence loss, and classification loss. The final loss is a composite of these, and accuracy as a singular metric will simply not summarize these well. In contrast, precision would reveal how many of the *predicted* bounding boxes were indeed correct, while recall reveals how many of the *true* bounding boxes were correctly predicted. mAP then combines both of these in a standard way across all predicted classes.

To illustrate, let's examine how loss functions and object detection metrics interplay through code snippets. The first example demonstrates a simplified custom loss function implementation:

```python
import tensorflow as tf

def custom_yolo_loss(y_true, y_pred, lambda_coord=5, lambda_noobj=0.5):
    # Assume y_true and y_pred are batched tensors containing bounding boxes, objectness scores, and class probabilities
    true_bboxes = y_true[..., 0:4] # x, y, w, h
    true_objness = y_true[..., 4:5] # 1 for object, 0 for background
    true_classes = y_true[..., 5:]

    pred_bboxes = y_pred[..., 0:4]
    pred_objness = y_pred[..., 4:5]
    pred_classes = y_pred[..., 5:]

    # Localization Loss (simplified) - measures difference between predicted and true bounding box parameters
    coord_loss = tf.reduce_sum(tf.square(true_bboxes - pred_bboxes) * true_objness) * lambda_coord

    # Confidence Loss - penalizes incorrect objectness scores
    obj_loss = tf.reduce_sum(tf.square(true_objness - pred_objness) * true_objness)
    noobj_loss = tf.reduce_sum(tf.square(true_objness - pred_objness) * (1 - true_objness)) * lambda_noobj

    # Classification Loss - penalizes incorrect class predictions only where an object exists
    class_loss = tf.reduce_sum(tf.keras.losses.categorical_crossentropy(true_classes, pred_classes) * true_objness)

    total_loss = coord_loss + obj_loss + noobj_loss + class_loss
    return total_loss

# Example usage
y_true = tf.random.normal(shape=(32, 13, 13, 5, 10), dtype=tf.float32) # Batch, grid, number of anchors, bounding box and classes
y_pred = tf.random.normal(shape=(32, 13, 13, 5, 10), dtype=tf.float32)
loss = custom_yolo_loss(y_true, y_pred)
print(f"Calculated loss: {loss.numpy()}")
```

This code snippet outlines a greatly simplified loss function where it explicitly works with bounding boxes, object presence and class probabilities. Notice how it makes no attempt to evaluate the *overall* correctness of an image, instead focusing on the objects within each image, where true labels and predicted labels are matched at the anchor box level in a spatial context. It will output only one loss.

The second example presents how one might evaluate mean average precision (mAP) using a metric library:

```python
import tensorflow as tf
import numpy as np

def calculate_iou(box1, box2):
    x1_1, y1_1, x2_1, y2_1 = box1
    x1_2, y1_2, x2_2, y2_2 = box2
    
    x_left = max(x1_1, x1_2)
    y_top = max(y1_1, y1_2)
    x_right = min(x2_1, x2_2)
    y_bottom = min(y2_1, y2_2)
    
    if x_right < x_left or y_bottom < y_top:
        return 0.0
    
    intersection_area = (x_right - x_left) * (y_bottom - y_top)
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
    
    iou = intersection_area / (area1 + area2 - intersection_area)
    return iou

def calculate_precision_recall(true_boxes, pred_boxes, iou_threshold=0.5):
    tp = 0
    fp = 0
    fn = 0
    
    if len(pred_boxes) == 0:
        fn = len(true_boxes)
        return 0, 0

    if len(true_boxes) == 0:
        fp = len(pred_boxes)
        return 0,0

    matched_pred = [False for _ in range(len(pred_boxes))]
    for true_box in true_boxes:
        match_found = False
        for i, pred_box in enumerate(pred_boxes):
            iou = calculate_iou(true_box[0:4], pred_box[0:4]) # first 4 values are box coordinates
            if iou >= iou_threshold and not matched_pred[i]:
                tp += 1
                matched_pred[i] = True
                match_found = True
                break
        if not match_found:
             fn += 1
    
    fp = sum([not matched for matched in matched_pred])

    precision = tp / (tp + fp) if (tp+fp) != 0 else 0
    recall = tp / (tp + fn) if (tp+fn) != 0 else 0
    
    return precision, recall


def average_precision(true_boxes, pred_boxes, iou_thresholds = np.arange(0.5, 1.0, 0.05)):
    precisions = []
    recalls = []
    for iou in iou_thresholds:
      precision, recall = calculate_precision_recall(true_boxes, pred_boxes, iou)
      precisions.append(precision)
      recalls.append(recall)
    return np.mean(precisions), np.mean(recalls)


# Dummy data
true_boxes = [np.array([20, 30, 80, 90, 0]),  np.array([150, 170, 220, 230, 1])] # box coordinates and class
pred_boxes = [np.array([22, 32, 82, 92, 0]), np.array([160, 180, 210, 240, 1]), np.array([300, 320, 350, 360, 2])]

average_p, average_r = average_precision(true_boxes, pred_boxes)
print(f"Average precision : {average_p:.4f}, Average recall: {average_r:.4f}")

```

This implementation demonstrates a simplified mAP calculation using numpy. While a production system would use more robust implementations, the underlying calculations and comparisons against true values to evaluate performance remain central. The output does not include accuracy, instead highlighting the ability of the model to correctly locate and classify objects across multiple threshold levels.

Finally, here is an example showing a simplified implementation of callback:

```python
import tensorflow as tf
import numpy as np

class MAPCallback(tf.keras.callbacks.Callback):
    def __init__(self, validation_data, iou_thresholds = np.arange(0.5, 1.0, 0.05)):
        super().__init__()
        self.validation_data = validation_data
        self.iou_thresholds = iou_thresholds

    def on_epoch_end(self, epoch, logs=None):
        if self.validation_data is None:
            return

        x_val, y_val = self.validation_data
        
        avg_precisions = []
        avg_recalls = []
        for image_idx in range(x_val.shape[0]):
            y_pred_img = self.model.predict(x_val[image_idx:image_idx+1])[0] # predictions are batched, need to index
            y_true_img = y_val[image_idx]  

            # Preprocess predicted bounding boxes and ground truths (replace this with your real conversion)
            predicted_boxes = []
            true_boxes = []

            for anchor_idx in range(y_pred_img.shape[0]): # iterate over anchor points
               for k in range(y_pred_img.shape[1]):
                  if y_pred_img[anchor_idx, k, 4] > 0.5: # objectness score > 0.5
                     predicted_boxes.append(y_pred_img[anchor_idx, k, :])
                  if y_true_img[anchor_idx, k, 4] == 1: # ground truth objects have label 1
                     true_boxes.append(y_true_img[anchor_idx, k, :])

            if len(predicted_boxes) > 0:
                average_precision_img, average_recall_img = average_precision(true_boxes, predicted_boxes, self.iou_thresholds)
                avg_precisions.append(average_precision_img)
                avg_recalls.append(average_recall_img)
        
        mean_ap = np.mean(avg_precisions) if len(avg_precisions) > 0 else 0
        mean_ar = np.mean(avg_recalls) if len(avg_recalls) > 0 else 0

        if logs is not None:
          logs['val_mAP'] = mean_ap
          logs['val_mAR'] = mean_ar


# Dummy data for callback
x_val_dummy = tf.random.normal(shape=(10, 416, 416, 3)) # batch size of 10
y_val_dummy = tf.random.normal(shape=(10, 13, 13, 5, 10), dtype=tf.float32)
validation_data = (x_val_dummy, y_val_dummy)

model = tf.keras.models.Sequential([
      tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(416, 416, 3)),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(13*13*5*10),
      tf.keras.layers.Reshape((13, 13, 5, 10))
]) # very basic model to demonstrate

optimizer = tf.keras.optimizers.Adam()
callback = MAPCallback(validation_data=validation_data)
model.compile(optimizer=optimizer, loss=custom_yolo_loss) # using custom loss from prior
model.fit(x_val_dummy, y_val_dummy, epochs=5, callbacks=[callback])
```

This code creates a custom callback that computes and logs mean average precision and mean average recall across the validation data at the end of each epoch. This demonstrates how such metrics, not standard 'accuracy,' are generally incorporated into the training process for object detection models such as YOLO. Note that the callback output now includes 'val_mAP' and 'val_mAR' but makes no mention of 'accuracy'.

For further study, I recommend exploring the concepts of bounding box regression, Intersection over Union (IoU), precision-recall curves, and the evaluation metrics outlined above. Consult papers describing the original YOLO architecture, and object detection tutorials that delve into performance evaluation using metrics appropriate for object localization and classification. Additionally, consider researching common object detection benchmark datasets to understand how model performance is reported across research publications. Focus on literature that explicitly discusses evaluation methodologies within object detection frameworks, and seek out resources describing metrics specific to bounding box regressions. Resources that offer a deep dive into object detection loss functions, and the rationale behind their designs, will also be helpful. These materials should provide a comprehensive understanding of how performance is measured and optimized in a typical YOLO workflow.
