---
title: "Are equivalent networks exhibiting shape discrepancies?"
date: "2025-01-30"
id: "are-equivalent-networks-exhibiting-shape-discrepancies"
---
The phenomenon of shape discrepancies between seemingly equivalent neural networks arises from the inherent non-convexity of the loss landscape during training and the influence of random initialization. This means that two networks, defined with identical architectures and trained on the same dataset, can ultimately converge to solutions with differing learned weights and, consequently, distinct weight distributions (shapes) within their parameter spaces. It's not that they are fundamentally *different* networks, but they are different *instantiations* of the same network.

My experience working with complex convolutional neural networks for image segmentation consistently illustrates this. I’ve seen instances where two identical UNets, initialized with different random seeds and trained under similar conditions, achieved comparable validation accuracy yet exhibited significantly varied distributions in their weight histograms. One might have a fairly unimodal, Gaussian-like distribution while another shows a more skewed or multi-modal pattern. These are not functionally superior or inferior; they simply represent different pathways through the optimization landscape.

The underlying mechanisms causing this are multifaceted. Firstly, the backpropagation algorithm is a gradient-based method that relies on local optimization. The initial random weights place the network in a specific region of the loss surface. As training progresses, the network follows the gradient towards a minimum. However, this minimum is not guaranteed to be the global optimum, and the particular path followed is heavily influenced by the initial starting point. Consequently, two identical networks started at different points are very unlikely to converge to the identical solution. They might both achieve a good local minimum, but each within its own basin. This is further exacerbated by the use of stochastic gradient descent (SGD) or its variants, which introduces further randomness into the optimization path. This randomness, inherent in mini-batch sampling and update direction noise, prevents the optimization path from being fully deterministic, even with identical initialization.

Furthermore, the choice of activation functions also plays a role. Nonlinear activation functions, while crucial for learning complex mappings, also contribute to the non-convex nature of the loss function. Different paths through the optimization process can result in different regions of the activation space being more heavily used, which in turn affects the learned weights.

The observation of shape discrepancies also extends beyond the weights themselves. Similar phenomena are often observed in the activation maps generated by different instances of seemingly equivalent networks. Although both networks might effectively classify an input image correctly, their intermediate representations might exhibit different levels of feature activation or have spatial feature maps that vary substantially. This further underscores that the same functionality can be achieved through different internal representations.

Now, let's look at some code examples. I will use Python with PyTorch.

**Code Example 1: Weight Histogram Comparison**

```python
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

# Define a simple CNN architecture
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool2d(2)
        self.fc = nn.Linear(16 * 16 * 16, 10) # Assuming 32x32 input
    
    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

# Create two CNN instances with different random seeds
torch.manual_seed(42) # Initial seed for reproducibility
cnn1 = SimpleCNN()
torch.manual_seed(123) # Different initial seed
cnn2 = SimpleCNN()

# Generate some random input data for training
data = torch.randn(64, 3, 32, 32)
labels = torch.randint(0, 10, (64,))

# Define loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer1 = optim.Adam(cnn1.parameters(), lr=0.001)
optimizer2 = optim.Adam(cnn2.parameters(), lr=0.001)

# Train the models for a few epochs
for epoch in range(50):
    optimizer1.zero_grad()
    outputs1 = cnn1(data)
    loss1 = criterion(outputs1, labels)
    loss1.backward()
    optimizer1.step()

    optimizer2.zero_grad()
    outputs2 = cnn2(data)
    loss2 = criterion(outputs2, labels)
    loss2.backward()
    optimizer2.step()
    
# Extract weights from the first convolutional layer for comparison
weights1 = cnn1.conv1.weight.detach().cpu().numpy().flatten()
weights2 = cnn2.conv1.weight.detach().cpu().numpy().flatten()

# Plot histograms
plt.hist(weights1, bins=50, alpha=0.5, label='CNN 1')
plt.hist(weights2, bins=50, alpha=0.5, label='CNN 2')
plt.xlabel("Weight Value")
plt.ylabel("Frequency")
plt.title("Weight Distribution Comparison")
plt.legend()
plt.show()
```

This example defines a very basic CNN and trains two instances, each with different initial random seeds. After training for a limited number of epochs (to highlight the discrepancy), the histograms of the first convolutional layer weights are plotted. You should observe variations in the distributions, illustrating the different shapes of these two “equivalent” networks' learned weights.

**Code Example 2: Activation Map Visualization**

```python
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import numpy as np

class ActivationVizCNN(nn.Module):
    def __init__(self):
      super(ActivationVizCNN, self).__init__()
      self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
      self.relu = nn.ReLU()

    def forward(self, x):
      x = self.relu(self.conv1(x))
      return x

# Create two CNN instances with different random seeds
torch.manual_seed(55)
cnn_act1 = ActivationVizCNN()
torch.manual_seed(66)
cnn_act2 = ActivationVizCNN()

# Example image
example_image = torch.randn(1, 3, 64, 64)

# Forward pass
activation1 = cnn_act1(example_image).detach().cpu().numpy()
activation2 = cnn_act2(example_image).detach().cpu().numpy()

# Visualize a single channel's activation
channel_index = 15 # Choose a channel to visualize
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.imshow(activation1[0, channel_index, :, :], cmap='viridis')
plt.title("Activation Map - CNN 1")
plt.colorbar()

plt.subplot(1, 2, 2)
plt.imshow(activation2[0, channel_index, :, :], cmap='viridis')
plt.title("Activation Map - CNN 2")
plt.colorbar()

plt.show()
```

This code demonstrates another facet. Here, two simple CNNs (without classification layers) are created with different random seeds. They are fed a random input, and the activation maps from the ReLU output are visualized. Observe that despite having the same architecture, the activation maps exhibit differing shapes and intensities, reflecting their distinct representations.

**Code Example 3: Training with Same Seed - Different Outcome**

```python
import torch
import torch.nn as nn
import torch.optim as optim

# Define a simple fully connected network
class SimpleFC(nn.Module):
    def __init__(self):
        super(SimpleFC, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(50, 2)

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Function to train network for demonstration
def train_network(model, data, labels, epochs=200):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.01)

    for epoch in range(epochs):
      optimizer.zero_grad()
      outputs = model(data)
      loss = criterion(outputs, labels)
      loss.backward()
      optimizer.step()
    return model


# Create two networks using the SAME seed initially
torch.manual_seed(77)
fc_net1 = SimpleFC()
torch.manual_seed(77)
fc_net2 = SimpleFC()

# Create random data and labels
data_size = 100
input_dim = 10
input_data = torch.rand(data_size, input_dim)
labels = torch.randint(0, 2, (data_size,))

# Train for same number of epochs but each is now trained *separately*
fc_net1 = train_network(fc_net1, input_data, labels)
fc_net2 = train_network(fc_net2, input_data, labels)

# Compare trained model weights
# Extract weights from the first linear layer
weights_fc1_1 = fc_net1.fc1.weight.detach().cpu().numpy().flatten()
weights_fc1_2 = fc_net2.fc1.weight.detach().cpu().numpy().flatten()
weights_fc2_1 = fc_net1.fc2.weight.detach().cpu().numpy().flatten()
weights_fc2_2 = fc_net2.fc2.weight.detach().cpu().numpy().flatten()


print(f"Mean weight diff fc1: {abs(weights_fc1_1 - weights_fc1_2).mean()}")
print(f"Mean weight diff fc2: {abs(weights_fc2_1 - weights_fc2_2).mean()}")

```

This final example is crucial. Even if the random number generators *are* seeded *identically*, the different training runs, because they occur in a slightly different sequence of memory accesses and computations, will diverge and ultimately converge to *different* solutions. This is because floating-point math, particularly at the GPU level, may not be deterministic to that degree. It is not sufficient to simply specify the same initial seed; the training itself is a source of variation. You will find that the mean weight difference is non-zero.

Regarding resource recommendations for further understanding:

For a deeper dive into the theory of optimization in neural networks, consult resources dedicated to non-convex optimization, stochastic gradient descent, and generalization in deep learning. Look for books or monographs covering topics like landscape analysis and the impact of initialization. Furthermore, examine publications that explore the loss surface and the influence of different optimization techniques, such as variations on momentum or adaptive learning rates. Also, exploring resources covering the theory behind different activation functions and their individual impacts on the gradients would be beneficial. Finally, materials that outline the probabilistic and statistical nature of model parameter estimates would also greatly aid in forming a strong conceptual basis.
