---
title: "Why aren't PBS_NODEFILE and PBS_JOBID set in Torque?"
date: "2025-01-30"
id: "why-arent-pbsnodefile-and-pbsjobid-set-in-torque"
---
Torque, a widely used resource manager, does not consistently populate the environment variables `PBS_NODEFILE` and `PBS_JOBID` within a submitted job's execution environment when the job is executed on a compute node. These variables, while commonly expected, often require careful configuration within Torque's job execution pipeline and understanding of the system’s setup to ensure availability. The omission is not a bug but rather a consequence of the default settings designed for optimal resource management.

The issue stems primarily from Torque's modular architecture, which separates job scheduling and execution. Unlike systems that tightly couple these functions, Torque operates with a degree of indirection. The `pbs_server` daemon, responsible for job scheduling, does not directly launch processes on compute nodes. Instead, it communicates with `pbs_mom` daemons on each node. These `pbs_mom` instances receive instructions to execute specific user scripts. The initial environment variables passed to the `pbs_mom` and subsequently to the user scripts are determined by the configuration of these daemons and the job submit command arguments, not by some default automatic mechanism within the `pbs_server`.

The `PBS_NODEFILE` environment variable, conventionally containing the list of nodes assigned to a job, is not automatically created by Torque because the `pbs_mom` daemons do not natively track which nodes are assigned to which job. The `pbs_mom` receives only the information needed to execute a given task on its specific node, not the entire cluster-level allocation. Therefore, generating the node file requires explicit user request.

Similarly, while `PBS_JOBID` seems intuitive, its absence is a result of how Torque isolates job execution environments. The job ID is generated by the `pbs_server` at job submission time, but this ID is not automatically communicated directly to every `pbs_mom` where the job might be executing. The `pbs_mom` primarily focuses on executing the received task based on a task identifier.

To illustrate this absence and the necessity for explicit actions to populate these variables, I will show three scenarios, representing different levels of access and control one might have when working with Torque.

**Scenario 1: Default Job Submission**

Consider the following simple batch script `test_script.sh` submitted to a Torque system:

```bash
#!/bin/bash
echo "Running on host: $(hostname)"
echo "PBS_NODEFILE: ${PBS_NODEFILE:-Not Set}"
echo "PBS_JOBID: ${PBS_JOBID:-Not Set}"
```

When submitted using `qsub test_script.sh`, the output might resemble:

```
Running on host: node123
PBS_NODEFILE: Not Set
PBS_JOBID: Not Set
```

As shown, `PBS_NODEFILE` and `PBS_JOBID` are not set by default. The script runs successfully on the assigned node, but it does not inherit the desired job allocation information. The `:-Not Set` construct in bash ensures we have output even if these environment variables do not exist. This demonstrates how common it is for users to encounter these variables as missing when submitting a job with no special configuration.

**Scenario 2: Utilizing Torque's -v Flag**

To pass a modified environment to the job execution environment, we can utilize the `-v` flag with `qsub`. The `-v` flag passes environment variables to the job. The command to submit a job and pass the Job ID environment using the command line would look something like `qsub -v PBS_JOBID=$PBS_JOBID test_script.sh`. This may not be practical as the `$PBS_JOBID` is local to the submitting node not the execution node.

This approach does not solve our `PBS_NODEFILE` issue, as the `PBS_NODEFILE` variable is not set by default anywhere in the submitting or execution context. However, we can pass a variable for testing. Consider the following updated `test_script.sh`:

```bash
#!/bin/bash
echo "Running on host: $(hostname)"
echo "PBS_NODEFILE: ${PBS_NODEFILE:-Not Set}"
echo "PBS_JOBID: ${PBS_JOBID:-Not Set}"
```

And a submission with the `-v` flag:

```bash
qsub -v PBS_JOBID=12345 test_script.sh
```

The output will then show:

```
Running on host: node123
PBS_NODEFILE: Not Set
PBS_JOBID: 12345
```
This approach will set PBS_JOBID to a fixed string or whatever string passed at the time of submission but it will not use the actual `PBS_JOBID` provided by the server. This workaround has limited use cases and does not meet the needs of most cluster users.

**Scenario 3: Generating Nodefile and Setting JobID within the Job**

To actually populate `PBS_NODEFILE` and have the correct `PBS_JOBID`, we need to modify the batch script to actively fetch this information from the Torque environment and create a local node file if needed. Consider a refined script `test_script_v2.sh`:

```bash
#!/bin/bash

# Get the assigned nodes, if not already set
if [ -z "$PBS_NODEFILE" ]; then
    NODELIST=$(cat "$PBS_NODEFILE" || qstat -f $PBS_JOBID | grep -i "Nodes =" | sed 's/.*= //')
    if [ -n "$NODELIST" ]; then
        #create a local nodefile
        echo "$NODELIST" | tr "," "\n" > local_nodefile
        PBS_NODEFILE="local_nodefile"
        export PBS_NODEFILE
    fi
fi

# Ensure we always use the correct job ID
if [ -z "$PBS_JOBID" ]; then
    PBS_JOBID=$(echo $PBS_TASKID | awk -F"." '{print $1}')
    export PBS_JOBID
fi

echo "Running on host: $(hostname)"
echo "PBS_NODEFILE: $PBS_NODEFILE"
echo "PBS_JOBID: $PBS_JOBID"
if [ -f local_nodefile ]; then
    echo "Content of nodefile:"
    cat local_nodefile
fi
```

Here’s a breakdown of the script. First it detects if `PBS_NODEFILE` already exists. If it does not the script attempts to extract the node allocation information using `qstat`, parsing the output to generate a local `local_nodefile`. If it cannot generate a list of nodes the `PBS_NODEFILE` will remain unset. Then a check to see if the `PBS_JOBID` is set is made and a value derived from `PBS_TASKID` if one does not exist. If the Job ID exists it is passed as is. The script outputs the environment variables as before but also outputs the contents of the local_nodefile if one was created.

Submitting `qsub test_script_v2.sh` results in an output similar to this:

```
Running on host: node123
PBS_NODEFILE: local_nodefile
PBS_JOBID: 12345
Content of nodefile:
node123
node124
node125
```

This refined approach illustrates how to programmatically generate the `PBS_NODEFILE` and ensure the correct `PBS_JOBID` value is used.

**Resource Recommendations**

For a more comprehensive understanding of Torque and its configuration, I would suggest reviewing the following resources, rather than relying solely on community forums:

1.  **Torque Administrator Guide:** This document contains critical information regarding the `pbs_mom` daemon, its settings, and environment variable configuration.
2.  **Torque User Guide:** This guide provides insights into job submission, batch scripts, and different options that impact the execution environment, specifically the `-v` flag.
3.  **Source Code Examination:** Directly exploring the source code of Torque's `pbs_mom` daemon can be beneficial for understanding the exact mechanism of variable inheritance and environment setup during task execution.
4.  **Local Cluster Documentation:** Each cluster often has custom configurations documented by its administrators. Consulting this resource may reveal cluster-specific settings that override the default Torque behavior.

In conclusion, the absence of `PBS_NODEFILE` and `PBS_JOBID` in Torque is not an oversight but an intended consequence of its flexible, modular design. Understanding this behavior is essential to effectively utilize Torque's capabilities within a cluster environment. The user must understand and programmatically retrieve the data required to populate these environment variables within job execution environments.
