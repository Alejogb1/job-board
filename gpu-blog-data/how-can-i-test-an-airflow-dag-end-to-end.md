---
title: "How can I test an Airflow DAG end-to-end with fixed input and mocked configuration using Python unit tests?"
date: "2025-01-30"
id: "how-can-i-test-an-airflow-dag-end-to-end"
---
End-to-end testing of Airflow DAGs with fixed inputs and mocked configurations necessitates a structured approach leveraging Airflow's testing utilities and Python's mocking capabilities. My experience developing and maintaining large-scale data pipelines within a financial institution highlighted the critical need for robust testing methodologies, and the following outlines a best-practice solution. The key lies in isolating the DAG's logic from external dependencies, enabling reproducible and reliable tests.

**1. Clear Explanation**

The core challenge in testing an Airflow DAG end-to-end involves simulating the execution environment while controlling input data and external system interactions.  Directly running a DAG for testing is generally undesirable due to its dependency on external resources, potentially leading to unpredictable results and slow test execution.  Instead, we leverage Airflow's `unittest` framework combined with Python's `unittest.mock` library. This allows us to mock external dependencies, such as database connections, API calls, or file system interactions, replacing them with controlled substitutes that return predefined outputs.  Simultaneously, we provide fixed input data to the DAG's operators, ensuring consistent test results.  The process involves constructing a test case for each DAG, mocking its dependencies within each test method, and asserting the expected behavior based on the provided inputs and mocked outputs.  Crucially, this method focuses on verifying the DAG's logic and data transformation steps, rather than the underlying infrastructureâ€™s reliability.

**2. Code Examples with Commentary**

**Example 1: Mocking a Database Connection**

This example showcases mocking a database interaction within a DAG.  Assume a DAG task utilizes a Postgres database.

```python
import unittest
from unittest.mock import patch
from airflow.models import DAG
from airflow.providers.postgres.operators.postgres import PostgresOperator
from datetime import datetime

with DAG(
    dag_id='test_dag',
    start_date=datetime(2023, 1, 1),
    schedule=None,
    catchup=False
) as dag:
    task1 = PostgresOperator(
        task_id='postgres_task',
        postgres_conn_id='postgres_default',
        sql="SELECT COUNT(*) FROM my_table WHERE value = {{ params.value }}",
        params={'value': 10}
    )


class TestPostgresDAG(unittest.TestCase):
    @patch('airflow.providers.postgres.operators.postgres.PostgresHook.get_conn')
    def test_postgres_task(self, mock_get_conn):
        # Mock the database connection to return a cursor with a predefined result
        mock_cursor = mock_get_conn.return_value.cursor.return_value
        mock_cursor.fetchone.return_value = (100,)  # Simulate 100 rows matching the condition

        dag.clear()  # Clear any existing DAG run state
        task1.run(start_date=datetime(2023, 1, 1), end_date=datetime(2023, 1, 1))

        # Assert that the task completed successfully (adjust based on your task's logic)
        self.assertTrue(task1.get_state() == 'success')


if __name__ == '__main__':
    unittest.main()
```
This code mocks `PostgresHook.get_conn`, providing a controlled cursor to simulate a database query result without actually connecting to a database.  The assertion verifies the task's state after execution.


**Example 2: Mocking an External API Call**

This example shows how to mock an API call using the `requests` library within a DAG.

```python
import unittest
from unittest.mock import patch
from airflow.models import DAG
from airflow.decorators import task
from datetime import datetime
import requests

with DAG(
    dag_id='api_dag',
    start_date=datetime(2023, 1, 1),
    schedule=None,
    catchup=False
) as dag:
    @task
    def api_call_task(value):
        response = requests.get(f"https://api.example.com/data?value={value}")
        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)
        return response.json()

    result = api_call_task(10)

class TestAPIDAG(unittest.TestCase):
    @patch('requests.get')
    def test_api_call_task(self, mock_get):
        mock_response = mock_get.return_value
        mock_response.status_code = 200
        mock_response.json.return_value = {'data': 'test_data'}

        result = api_call_task(10)

        self.assertEqual(result, {'data': 'test_data'})

if __name__ == '__main__':
    unittest.main()

```
Here, `requests.get` is mocked to return a controlled response, preventing actual network calls and ensuring consistent test results.


**Example 3: Mocking File System Interactions**

This example demonstrates mocking file system operations using `mock_open` from `unittest.mock`.  This is crucial for tasks involving reading from or writing to files.

```python
import unittest
from unittest.mock import patch, mock_open
from airflow.models import DAG
from airflow.decorators import task
from datetime import datetime

with DAG(
    dag_id='file_dag',
    start_date=datetime(2023, 1, 1),
    schedule=None,
    catchup=False
) as dag:
    @task
    def file_processing_task(filepath):
        with open(filepath, 'r') as f:
            content = f.read()
        return content

    result = file_processing_task('/path/to/file.txt')

class TestFileDAG(unittest.TestCase):
    @patch('builtins.open', new_callable=mock_open, read_data='test_file_content')
    def test_file_processing_task(self, mock_open):
        result = file_processing_task('/path/to/file.txt')
        self.assertEqual(result, 'test_file_content')

if __name__ == '__main__':
    unittest.main()
```

This uses `mock_open` to replace the built-in `open` function, providing a mock file object with predefined content.  This avoids relying on the existence of a specific file.


**3. Resource Recommendations**

For a deeper understanding of Airflow's testing capabilities, I recommend consulting the official Airflow documentation on testing.  Further, a comprehensive guide on Python's `unittest` and `unittest.mock` libraries will prove invaluable.  Finally, exploring resources on best practices for unit testing in Python will improve your overall testing strategy.  Remember that thorough testing requires a combination of unit, integration, and end-to-end tests for complete coverage.  Prioritize the principles of isolation, testability, and maintainability when designing your DAGs and tests.  This approach ensures your Airflow pipelines are robust and reliable, mitigating risks associated with complex data flows.
