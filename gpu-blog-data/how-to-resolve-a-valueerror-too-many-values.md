---
title: "How to resolve a 'ValueError: too many values to unpack' error when using tf.keras.preprocessing.image_dataset_from_directory?"
date: "2025-01-30"
id: "how-to-resolve-a-valueerror-too-many-values"
---
The `ValueError: too many values to unpack` encountered when utilizing `tf.keras.preprocessing.image_dataset_from_directory` almost invariably stems from a mismatch between the expected and actual number of elements returned by the generator's `__getitem__` method.  This typically arises from an incorrect assumption about the structure of the data yielded by the function, often related to the `label_mode` parameter. In my experience troubleshooting similar issues in production-level image classification models, this misunderstanding frequently led to hours of debugging, emphasizing the importance of meticulous data inspection.

**1. Clear Explanation:**

`tf.keras.preprocessing.image_dataset_from_directory` generates batches of image data and labels. The specific output format is dictated by the `label_mode` argument.  If `label_mode` is set to 'binary', 'categorical', or 'int', the generator yields tuples of the form `(images, labels)`.  However, if `label_mode` is set to 'raw', or if you're operating on a dataset without labels (which is valid but uncommon in supervised learning), the generator simply produces a tuple containing only the images.  The error arises when code expecting a `(images, labels)` tuple attempts to unpack a single `images` tuple, leading to the `ValueError`.

Further complicating matters, the `images` and `labels` themselves can be nested structures depending on batch size. The `images` will always be a NumPy array with shape `(batch_size, height, width, channels)`, but the `labels` can be a 1D NumPy array (`shape=(batch_size,)`) for 'int' or 'binary' mode, or a 2D NumPy array (`shape=(batch_size, num_classes)`) for 'categorical' mode. Failure to account for this dimensionality can lead to unpacking errors.

Another less common source of error involves specifying a custom `image_size` that doesn't match the actual dimensions of your images.  If you misjudge the size, resulting images may be improperly structured, leading to unexpected outputs and potentially triggering the unpacking error, although this will often manifest as a different error first.  This emphasizes the importance of pre-processing steps to standardize image sizes.

**2. Code Examples with Commentary:**

**Example 1: Correct Usage with Binary Labels**

```python
import tensorflow as tf

dataset = tf.keras.preprocessing.image_dataset_from_directory(
    'path/to/your/image/directory',
    labels='inferred',  # Automatically infers labels from subdirectory names
    label_mode='binary',  # Binary classification
    image_size=(224, 224),
    batch_size=32
)

for images, labels in dataset:
    # Correct unpacking; images and labels are appropriately structured
    print(images.shape)  # Output: (32, 224, 224, 3)
    print(labels.shape)  # Output: (32,)
    # Process images and labels
```

This demonstrates the proper way to handle a binary classification dataset.  The `label_mode='binary'` parameter ensures that the generator returns a tuple with the images and their corresponding binary labels.  The unpacking `images, labels` works correctly because the generator returns two values.

**Example 2: Incorrect Usage â€“ Mismatched Unpacking**

```python
import tensorflow as tf

dataset = tf.keras.preprocessing.image_dataset_from_directory(
    'path/to/your/image/directory',
    labels='inferred',
    label_mode='raw',  # This is the source of the error!
    image_size=(224, 224),
    batch_size=32
)

for images, labels in dataset: # Incorrect unpacking!
    # This will throw the ValueError: too many values to unpack
    print(images.shape)
    print(labels.shape)
```

This example highlights the crucial role of `label_mode`.  By setting `label_mode='raw'`, the generator only returns the image data, and there is no accompanying `labels` element. Attempting to unpack into `images, labels` will inevitably result in the error because only a single element is produced.

**Example 3: Handling a Dataset Without Labels**

```python
import tensorflow as tf

dataset = tf.keras.preprocessing.image_dataset_from_directory(
    'path/to/your/image/directory',
    labels=None,  # No labels provided
    image_size=(224, 224),
    batch_size=32
)

for images in dataset: # Correct unpacking; only images are returned
    # Correctly unpacks the single element from the generator
    print(images.shape) # Output: (32, 224, 224, 3)
    # Process images only
```

Here, we correctly handle a dataset lacking labels.  The `labels=None` parameter instructs the generator to only yield image data.  The unpacking is adjusted accordingly, only receiving the `images` variable.  Failure to modify the unpacking in this scenario would also lead to the `ValueError`.

**3. Resource Recommendations:**

The official TensorFlow documentation is your primary resource.  Carefully review the `tf.keras.preprocessing.image_dataset_from_directory` function's parameters and return values. Supplement this with a strong understanding of NumPy array manipulation and data structures in Python.  Consider consulting established machine learning textbooks focusing on image processing and deep learning for a broader context on data handling in this domain.  Thorough examination of your dataset using visualization tools and descriptive statistics will significantly improve your ability to identify potential data structure issues before they manifest as runtime errors.  Finally, a good debugging strategy involving print statements within loops can aid in pinpointing exactly which part of your pipeline is producing problematic data.
