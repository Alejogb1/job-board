---
title: "How can I execute multiple commands within a running temporary container?"
date: "2025-01-30"
id: "how-can-i-execute-multiple-commands-within-a"
---
Docker containers, fundamentally designed to encapsulate a single primary process, often present a challenge when the need arises to execute multiple commands *within* their isolated environment, particularly in temporary or debugging scenarios. Directly using `docker exec` repeatedly, while viable, becomes cumbersome and error-prone for anything beyond trivial cases. My experience building continuous integration pipelines has highlighted several robust approaches to address this, primarily revolving around crafting a sequence of commands within a single `docker exec` call, or pre-configuring an entrypoint to facilitate this pattern.

The core difficulty lies in the fact that `docker exec` initiates a new process within the container. Executing a command like `docker exec my-container command1` then `docker exec my-container command2` results in two separate process instantiations, not a sequential execution within a single shell context as one might intuitively expect. Therefore, to accomplish true sequential execution we need to invoke a shell within the container and pass the desired commands to it.

### Sequential Execution within a Shell

The most common and straightforward approach is to encapsulate the desired commands within a single shell invocation using the `-c` flag. This flag instructs the target shell (typically `/bin/sh` or `/bin/bash` within the container) to execute the supplied string as a command. The shell then interprets the string, executing each command sequentially, respecting pipes, redirects, and other shell idioms.

The key is understanding how to structure the command string. We need to join multiple commands using delimiters understood by the shell. Common choices are `&&` (execute the next command only if the previous succeeded) or `;` (execute the next command unconditionally).

Here's an example illustrating this, assuming we have a container named `my_temp_container`:

```bash
docker exec my_temp_container /bin/sh -c "mkdir /tmp/test_dir && touch /tmp/test_dir/test_file && echo 'Hello' > /tmp/test_dir/test_file"
docker exec my_temp_container cat /tmp/test_dir/test_file #Verification
```
**Commentary:** In this example, I use `docker exec` to initiate `/bin/sh` within the container. The `-c` flag is used to pass a string that includes three commands. First, `mkdir /tmp/test_dir` attempts to create a directory, and only upon success will `touch /tmp/test_dir/test_file` create a file within it.  Lastly, we echo some text into that file.  The second `docker exec` command verifies the output. The `&&` operator ensures that the second and third commands will only execute after their predecessors succeed.  Using `;` instead of `&&` could be an acceptable alternative if all commands need to run whether the prior commands worked or not.

The benefit of this method is its simplicity. However, the command string can become unwieldy when dealing with complex sequences or long commands.  Furthermore, this approach requires that the shell environment is available within the target container.

### Using a Here Document

When dealing with multiple lines of commands, constructing a single string becomes error-prone. A more readable approach utilizes a here document, a shell construct allowing multi-line input redirection. This approach passes the multi-line command string into the shell. This syntax requires the definition of a 'delimiter'. This delimiter must be unique and not appear within the command sequence. In our example, we will use `EOF`.

```bash
docker exec my_temp_container /bin/sh << EOF
  mkdir /tmp/test_dir2
  touch /tmp/test_dir2/test_file2
  echo 'Hello Again' > /tmp/test_dir2/test_file2
  ls -l /tmp/test_dir2
EOF
docker exec my_temp_container cat /tmp/test_dir2/test_file2 #Verification
```
**Commentary:** Here, the `<< EOF` initiates a here document. The shell reads all input lines until it encounters `EOF` on a line by itself. Each of those lines are treated as separate commands.  This approach increases readability, especially for complex command sequences. As before, the second `docker exec` command provides verification. The here document approach avoids issues with complicated command escaping.

This second approach improves command readability and management, but it still depends on an available shell environment within the container.

### Executing a Script within the Container

If you need to execute many commands repeatedly, it becomes beneficial to create a script inside the container and then invoke that script via `docker exec`. This script can be created dynamically within the container or built into the image. In scenarios where you need to perform a common series of actions each time you start the container, the script creation can be added to the container build process. When performing debugging, you might create it on the fly. This approach introduces a level of permanence compared to the single-command line solutions.

Consider a scenario where a container needs to compile and run code and then send the result over the network.  We could accomplish the following via:

```bash
docker exec my_temp_container /bin/sh -c "echo '#!/bin/sh\n gcc -o /tmp/app /tmp/source.c && /tmp/app' > /tmp/run.sh && chmod +x /tmp/run.sh"
docker exec my_temp_container /bin/sh -c "echo '#include <stdio.h>\nint main() { printf(\"Hello from C\"); return 0; }' > /tmp/source.c"
docker exec my_temp_container /tmp/run.sh
```
**Commentary:** In this approach, the first `docker exec` call creates a bash script named `run.sh` within the container. We write a simple script that compiles source.c and runs the resulting executable.  We then need to make it executable.  The second `docker exec` creates `/tmp/source.c` which provides some test code to execute. The final `docker exec` command then executes the script within the container.  This approach is more involved but provides for a more permanent solution. The creation of the script within the container could also be automated in a pipeline or the script could be pre-created when the container is built using `COPY` directive in a `Dockerfile`.

### Considerations and Best Practices

When implementing any of these approaches, keep in mind several factors. First, the target container must have a shell (e.g., `/bin/sh`, `/bin/bash`) available unless you are executing a single executable program. Second, overly complex command strings can become difficult to debug, hence the advantages of using here documents or scripts. Third, ensure that any temporary files or directories created are cleaned up appropriately after use to prevent cluttering the containerâ€™s file system if this is a production process. Fourth, it's often better to create a custom Docker image with pre-configured tools or scripts if you will use them frequently, rather than relying solely on dynamic command execution. Finally, keep in mind that the permissions of the user that `docker exec` executes within the container defaults to root and you may want to utilize `-u` flag to specify a user to avoid privilege escalation.

### Resource Recommendations
To further explore container interactions, I would recommend consulting the following resources:
*   Docker documentation on `docker exec`.
*   Guides on shell scripting for more advanced command manipulation within containers.
*   Books or online tutorials on Docker best practices.
*   Examples of pipeline or orchestration tools such as Gitlab CI, or Jenkins that use `docker exec`
These resources will allow you to better adapt the presented techniques for diverse use-cases. In conclusion, while Docker containers are designed around single primary processes, various techniques facilitate executing multiple commands within their isolated environment, utilizing shell invocations, here documents, or custom scripts.  Selecting the appropriate method depends heavily on the complexity of the commands, the need for persistence and the overall desired user experience.
