---
title: "How do I obtain variable values during each GEKKO optimization iteration?"
date: "2025-01-30"
id: "how-do-i-obtain-variable-values-during-each"
---
The core challenge in accessing variable values during each GEKKO optimization iteration stems from the inherent asynchronous nature of the solver's internal operations.  Directly accessing variables within the main loop is generally unproductive because the solver operates independently, updating variables only after completing a full iteration.  My experience with large-scale process optimization projects has shown that employing callbacks and strategically leveraging GEKKO's reporting features provides the most robust solution.

**1. Clear Explanation:**

GEKKO's solver operates in an iterative fashion, meaning it repeatedly evaluates the objective function and constraints to find the optimal solution.  Unlike explicit looping constructs, the solver's iterations are internal and not directly controllable through standard Python loops. Attempting to access variable values inside a `for` loop alongside the solver will almost always yield incorrect or stale values.  The solver updates its internal variable estimates independently, often asynchronously relative to the main program flow.

The optimal approach involves utilizing GEKKO's callback functionality.  Callbacks are functions that are executed at specific points during the solver's operation, providing access to the current state of variables.  Specifically, the `options` parameter within the `GEKKO` model allows for configuring the solver's output frequency, enabling retrieval of variable values after each iteration.  Furthermore, careful use of GEKKO's built-in reporting mechanisms allows for efficient logging of relevant data without requiring complex manual tracking.

The key is to decouple the observation of variable values from the solver's execution loop.  Instead of trying to force access within the loop, we register a function that is called *by* the solver at the end of each iteration. This provides a clean and efficient way to monitor the iterative progress without interfering with the solverâ€™s algorithm.  This method prevents race conditions and guarantees the reported values accurately reflect the solver's state at that particular iteration.

**2. Code Examples with Commentary:**

**Example 1: Simple Callback for Variable Monitoring**

```python
from gekko import GEKKO

m = GEKKO(remote=False)  # Local solver

x = m.Var(value=0, lb=0, ub=10)
y = m.Var(value=0, lb=0, ub=10)
m.Equation(x**2 + y**2 == 25)
m.Obj((x-3)**2 + (y-4)**2)

# Callback function to print variable values
def callback_function(i):
  print(f"Iteration: {i}, x: {x.value[0]}, y: {y.value[0]}")

m.options.IMODE = 3 # Steady-state optimization
m.options.SOLVER = 3 # IPOPT solver
m.options.SAVE_EACH_ITERATION = True
m.solve(disp=False, callback=callback_function)
```

This example utilizes a simple callback function that is executed at every iteration. The `SAVE_EACH_ITERATION` option ensures GEKKO stores the variable values after each iteration. The `callback` argument then passes this function to the solver.  Observe that the callback receives the iteration number as input, allowing for context in data logging.

**Example 2:  Logging to a File**

```python
from gekko import GEKKO
import csv

m = GEKKO(remote=False)

# ... (Define variables and equations as in Example 1) ...

def log_to_file(i):
    with open('iteration_data.csv', 'a', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow([i, x.value[0], y.value[0]])

# ... (Solver options and solving as in Example 1, replacing callback with log_to_file) ...
```

This demonstrates more sophisticated data handling.  Instead of printing directly, the values are appended to a CSV file.  This approach is particularly beneficial for large optimization runs, enabling offline analysis of the iterative progress.  The CSV format allows for easy importing into data analysis software for visualization and further processing. Note the use of `'a'` in `open()` for appending data to the file in each iteration.


**Example 3:  Conditional Callback based on Objective Function Value**

```python
from gekko import GEKKO

m = GEKKO(remote=False)

# ... (Define variables and equations as in Example 1) ...

objective_tolerance = 0.1

def conditional_callback(i):
  if abs(m.options.OBJFCNVAL-m.options.OBJFCNVAL_prev) < objective_tolerance:
      print(f"Objective function converged at iteration {i}, x: {x.value[0]}, y: {y.value[0]}")
  else:
    print(f"Iteration: {i}, x: {x.value[0]}, y: {y.value[0]}, Objective: {m.options.OBJFCNVAL}")


m.options.IMODE = 3
m.options.SOLVER = 3
m.options.SAVE_EACH_ITERATION = True
m.solve(disp=False, callback=conditional_callback)
```

This example introduces a conditional callback, triggered only when the change in the objective function value falls below a defined tolerance. This allows focusing on significant changes during the optimization process, potentially improving efficiency for large problems.  It leverages GEKKO's built-in `OBJFCNVAL` to monitor convergence.


**3. Resource Recommendations:**

I would recommend reviewing the official GEKKO documentation, paying close attention to the sections on solvers, options, and callbacks.  Familiarizing yourself with the solver's internal workings and its communication mechanisms will significantly enhance your understanding of this process.  Additionally, studying example scripts within the GEKKO repository can provide practical insights into implementing and adapting these techniques for various optimization problems.  Exploring the documentation on IPOPT, the solver utilized in these examples, will further deepen your understanding of the underlying optimization algorithm. Finally, investing time in learning the fundamentals of numerical optimization techniques, such as gradient descent, will provide crucial context and aid in troubleshooting.  These resources will enable you to effectively design and debug your optimization strategies.
