---
title: "Fine-Tuning & Merging LLMs: A Practical Guide"
date: "2024-11-16"
id: "fine-tuning--merging-llms-a-practical-guide"
---

dude so this video was all about fine-tuning llms and merging models  like seriously mind-blowing stuff  the guy maxim laon  some serious ml scientist at liquid ai  laid it all out  think of it as a supercharged tutorial for making language models even better and combining them into ultimate beasts

so the setup  he starts by explaining the llm training life cycle  it's like three steps  first  pre-training  think of it as giving the model a massive diet of text data  it's learning to predict the next word  the result is a base model  it’s pretty good but it's a bit of a know-it-all  just autocompleting rather than answering questions

then comes supervised fine-tuning sft  this is where things get interesting  you give the model pairs of questions and answers  it’s learning to actually answer the questions instead of just showing off  think of it as teaching a parrot to speak rather than just mimicking sounds

finally  preference alignment  here's where you guide the model's personality and behavior  you give it examples of good and bad answers  like showing a toddler what a good toy versus a bad toy is  this gets you a chat model  something more conversational and hopefully less prone to saying incredibly offensive things

one visual cue  he uses a flow chart to explain when to use prompt engineering vs fine-tuning  it's like a decision tree  if prompt engineering does the job  great  if not  can you easily create an instruction dataset  if yes  fine-tuning's your friend  if no  maybe rethink the project  another visual cue is his super-detailed example of an sft sample  instruction system prompt user prompt all labeled  makes it totally clear

key ideas  the first is supervised fine-tuning itself  it's not just about memorizing  it's about understanding the relationship between questions and answers  he mentions using synthetic data generated by other models to create high-quality training sets  this is key because gathering real human-generated data at scale is, well, expensive

second key idea model merging  this is where the magic happens  he showed this insane family tree of merged models  it was nuts  the idea is that you can combine several fine-tuned models to create something even more powerful  think of it like combining the strengths of various superheroes into one ultimate being

resolution  he wraps up by mentioning a few different model merging techniques  slurp dare and the hilarious pass-through method  pass-through is basically stacking layers from different models  he even made a model called meta llama 320b instruct by repeating layers of llama  it's ridiculous and amazing  it’s a testament to how much we still don't understand how these models work


here are some code snippets to illustrate some of the concepts  remember  these are simplified examples but illustrate the main ideas

**supervised fine-tuning with transformers**


```python
from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments

model_name = "decapoda-research/llama-7b-hf"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

#sample data
train_data = [
    {"instruction": "what is the capital of france", "output": "paris"},
    {"instruction": "what is the highest mountain in the world", "output": "mount everest"},
    #more examples here...
]

training_args = TrainingArguments(
    output_dir="./results",
    per_device_train_batch_size=4,
    num_train_epochs=3,
    #other arguments here...
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_data,
    #other arguments here...
)

trainer.train()
```

this code uses the hugging face transformers library  it loads a model  a tokenizer  and then trains it on a simple dataset of question-answer pairs  you’d need to adjust  batch size, learning rate and other hyperparameters to make it actually work

**model merging with merge-kit (conceptual)**

```python
#this is a simplified representation  merge-kit uses more complex methods
import merge_kit # assuming a simplified merge_kit library

model1 = load_model("path/to/model1")
model2 = load_model("path/to/model2")

merged_model = merge_kit.merge(model1, model2, method="slurp") #slurp is one method

save_model(merged_model, "path/to/merged_model")
```

this illustrates the basic idea  you'd load two models and use a merging function  merge kit has many more options and details

**data filtering (conceptual)**


```python
import re

def filter_data(data):
    filtered_data = []
    for item in data:
        if "i cannot" not in item["output"].lower(): #simple rule-based filter
            if len(item["output"]) > 50: #remove short answers
                filtered_data.append(item)
    return filtered_data
data = [
    {"instruction": "what is the meaning of life?", "output": "42"},
    {"instruction": "write a poem about a cat", "output": "i cannot answer that question"},
    {"instruction": "explain quantum physics", "output": "as an ai i cannot answer that question"}
]
filtered_data = filter_data(data)
print(filtered_data)
```

this is a really basic example of filtering a dataset  you’d often use much more sophisticated methods  like using another llm to judge the quality of the samples

man  that was a lot  but hopefully  that gives you a pretty good overview  it’s a super exciting field  lots of opportunities to make some truly wild stuff  plus  the dude’s presentation style was awesome  so casual and informative  definitely worth checking out the whole thing
