---
title: "How to Build a Chatbot That Remembers You with Python"
date: "2024-11-29"
id: "2961"
---

dude so this video was _amazing_ it was like a deep dive into building personalized chatbots but without all the stuffy formality you know the whole point was showing how to make a chatbot remember stuff about you so you don't have to keep repeating yourself like a broken record it's all about making your chatbot interactions more natural and less repetitive think of it as teaching your bot to have a _memory_

okay so visual cues right off the bat there's this meme the five tiers of personalization it's hilarious and really sets the stage for the whole thing then there's a bunch of code flying across the screen python mostly with openai's api calls you know the usual suspects and finally there's that moment where the guy pretends to screenshot someone's api keyâ€”classic

the main ideas are centered around different levels of personalization using large language models llms it's not just about _what_ your bot remembers but _how_ efficiently it remembers the first level is no personalization total amnesia your bot is like a goldfish with a really good vocabulary then he goes through different levels baking info into the system prompt using message history entity memory (remembering specific traits) and finally embedding everything in a vector database like pine cone super cool stuff right

let me break down two key concepts first system prompts imagine it's like giving your bot a set of instructions before each conversation like "you are a helpful assistant who always speaks in pirate speak" it sets the context but it's kinda rigid you gotta change the prompt every time you want to change the bot's behavior it's like hard coding instructions

then there's entity memory this is where it gets _really_ clever instead of dumping the whole conversation history into the llm you only feed it the relevant bits like "user likes ramen user dislikes red lobster" this is much more efficient it's like giving your bot a highlight reel instead of a whole movie makes it faster cheaper and a lot less overwhelming for the llm

the resolution is that building a truly personalized chatbot isn't about cramming everything into the llm's memory its about being smart and selective using techniques like entity extraction vector databases and carefully crafted prompts you can create a chatbot that feels like it actually knows you without breaking the bank or melting your servers

now for the code snippets this is where it gets _real_

first the f tier the baseline no memory

```python
import openai

openai.api_key = "YOUR_API_KEY"

response = openai.Completion.create(
  engine="text-davinci-003",
  prompt="tell me a joke",
  max_tokens=100
)

print(response.choices[0].text)
```

this is just a simple openai api call no context no memory just a pure zero-shot prompt

next the d tier using the system prompt

```python
import openai

openai.api_key = "YOUR_API_KEY"

system_message = "you are a helpful assistant my name is bob and i am a software engineer i dislike chocolate"

response = openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[{"role": "system", "content": system_message}, {"role": "user", "content": "what do you know about me"}],
  max_tokens=100
)

print(response.choices[0].message.content)

```

here we add a system message it's like setting the stage for the conversation the llm now has some context but it's still limited

finally the a tier using embeddings and a vector database this is the real magic

```python
import openai
from langchain.embeddings import OpenAIEmbeddings
import pinecone

# initialize openai and pinecone
openai.api_key = "YOUR_API_KEY"
pinecone.init(api_key="YOUR_PINECONE_API_KEY", environment="YOUR_PINECONE_ENVIRONMENT")

# create a pinecone index
index_name = "my-chatbot-index"
index = pinecone.Index(index_name)

# embed user preferences and save to pinecone
embeddings = OpenAIEmbeddings()
user_preferences = "likes: pizza, dislikes: broccoli"
embedding = embeddings.embed_query(user_preferences)
index.upsert([(user_preferences, embedding)])

# query pinecone for recommendations based on user preferences
query = "what should i eat for dinner"
query_embedding = embeddings.embed_query(query)
results = index.query(query_embedding, top_k=1)
recommendation = results.matches[0].values

print(recommendation)
```

this is where langchain and pinecone come in we embed user preferences store them in pinecone and then retrieve similar preferences based on the current conversation it's not the full code but gives you an idea of how it works it's all about leveraging vector similarity search to efficiently manage and retrieve user specific info

so yeah that's the video in a nutshell lots of cool stuff definitely check out the video yourself if you're interested in building awesome personalized chatbots remember those code snippets they'll save you a ton of time and headaches plus you'll finally have a chatbot that actually _gets_ you
