---
title: "How to Build a Chatbot That Remembers You with Python"
date: "2024-11-29"
id: "2961"
---

This video provided a detailed exploration of building personalized chatbots, focusing on making interactions more natural by enabling chatbots to remember details about users. The content is practical and avoids unnecessary formality, making it accessible yet impactful.

## Key Takeaways

### Engaging Visuals and Humor

The video begins with a clever meme illustrating the "five tiers of personalization," effectively setting the stage. It includes:

- Code demonstrations using Python and OpenAI's API.
- A humorous moment where the presenter pretends to screenshot someone's API key, adding levity to the technical explanations.

### Levels of Personalization

The video explores different levels of chatbot personalization:

1. **No Personalization (Baseline)**: The chatbot operates without memory, akin to a goldfish with an extensive vocabulary.
2. **System Prompts**: Embedding instructions in the prompt to establish context.
3. **Message History**: Using prior conversation history to inform responses.
4. **Entity Memory**: Storing and retrieving specific user traits.
5. **Vector Databases**: Embedding and retrieving information from vector databases (e.g., Pinecone) for advanced personalization.

---

## Key Concepts Explained

### 1. System Prompts

System prompts act as predefined instructions for the chatbot, setting the context for conversations. For example:

> "You are a helpful assistant who always speaks in pirate speak."

However, this approach can be rigid, as it requires manual adjustments for changing the bot's behavior.

### 2. Entity Memory

Entity memory optimizes efficiency by storing and recalling only relevant user details. For instance:

- Instead of presenting the entire conversation history to the LLM, the chatbot might remember specific preferences like:
  - _"The user enjoys ramen but dislikes seafood."_

This reduces computational load and costs while improving response relevance.

---

## Efficient Personalization

The video emphasizes that building a personalized chatbot isn’t about overloading the LLM with all possible data. Instead, it’s about:

- Selectively managing information.
- Using tools like **entity extraction**, **vector databases**, and **well-crafted prompts**.

This strategy ensures cost-effectiveness, scalability, and a user experience that feels genuinely intuitive.

---

## Code Snippets Demonstrated

### Baseline (No Memory)

A basic API call without any personalization:

```python
import openai

openai.api_key = "YOUR_API_KEY"

response = openai.Completion.create(
  engine="text-davinci-003",
  prompt="tell me a joke",
  max_tokens=100
)

print(response.choices[0].text)
```

This is a simple, zero-shot prompt with no memory or context.

Adding System Prompts

Introducing context through a system message:

```python
import openai

openai.api_key = "YOUR_API_KEY"

system_message = "You are a helpful assistant. My name is Bob, and I am a software engineer who dislikes chocolate."

response = openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[
      {"role": "system", "content": system_message},
      {"role": "user", "content": "What do you know about me?"}
  ],
  max_tokens=100
)

print(response.choices[0].message.content)
```

This method allows the bot to operate with some predefined context but remains limited.

Advanced Personalization with Vector Databases

Leveraging embeddings and vector databases for dynamic memory:

```python
import openai
from langchain.embeddings import OpenAIEmbeddings
import pinecone

# Initialize OpenAI and Pinecone
openai.api_key = "YOUR_API_KEY"
pinecone.init(api_key="YOUR_PINECONE_API_KEY", environment="YOUR_PINECONE_ENVIRONMENT")

# Create a Pinecone index
index_name = "my-chatbot-index"
index = pinecone.Index(index_name)

# Embed user preferences and store in Pinecone
embeddings = OpenAIEmbeddings()
user_preferences = "likes: pizza, dislikes: broccoli"
embedding = embeddings.embed_query(user_preferences)
index.upsert([(user_preferences, embedding)])

# Query Pinecone for recommendations based on preferences
query = "What should I eat for dinner?"
query_embedding = embeddings.embed_query(query)
results = index.query(query_embedding, top_k=1)
recommendation = results.matches[0].values

print(recommendation)
```

This demonstrates how to use tools like LangChain and Pinecone to embed and retrieve user-specific information efficiently. By employing vector similarity search, chatbots can manage and utilize user data effectively.

## Conclusion

The video highlights practical steps for building chatbots that feel personalized and responsive without excessive computational demands. By combining techniques like entity memory, embeddings, and vector databases, developers can create chatbots that genuinely “understand” users.
