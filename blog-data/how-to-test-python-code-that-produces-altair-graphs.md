---
title: "How to Test Python code that produces Altair graphs?"
date: "2024-12-15"
id: "how-to-test-python-code-that-produces-altair-graphs"
---

well, that's a question i’ve bumped into a few times, and honestly, it's not as straightforward as testing a simple function. you're not just checking for a specific output value, but a visual structure, a data representation. i've been there, staring at pipelines producing complex charts and wondering how to assert that things are actually… well, correct. i remember the days back at my old gig where we were doing massive geospatial data processing, and the final check was always a map. if it was wrong, something in the pipe had gone rogue, and often it was some subtle change in the coordinate system that led to entire country shapes being all weird. testing that with usual unit tests was a nightmare.

let's break this down like we are troubleshooting a system. the core issue is that altair renders json specifications that are then interpreted by a javascript renderer. so, directly testing pixel output is a no-go for most scenarios and definitely not something we wanna be doing in an automated testing environment. instead, we want to focus on testing the json specification which can be quite verbose. the approach i've landed on, after a lot of trial and error, is to test this json structure and make sure that our data transformations lead to consistent json output. we have to think about what things could go wrong, in a data oriented way, if we just test that the json is a blob of text then we will miss out a lot.

firstly, the most simple, obvious check you can do, is to verify the basic structure. does the generated json contain the keys we expect it to have? lets say you expect a chart to have a 'mark' object, a 'encoding' object and a 'data' object. if a particular function does not produce one of them your pipeline is wrong. here's a simplistic example of such a test:

```python
import altair as alt
import json
import unittest

class test_altair_json_structure(unittest.TestCase):

    def test_basic_chart_structure(self):
        chart = alt.Chart(
            alt.Data(values=[{"x": 1, "y": 2}, {"x": 3, "y": 4}])
        ).mark_point().encode(x="x", y="y")

        chart_json = json.loads(chart.to_json())

        self.assertIn("mark", chart_json)
        self.assertIn("encoding", chart_json)
        self.assertIn("data", chart_json)

```
this test can be further enhanced to be less brittle. if you know that the mark should be a string and not something else you can add that check. in the end you will have a series of asserts for the basic structure, type and names of keys in the generated json output. this type of test helps you find out when you accidentally mispelled a key or if a pipeline produces an object with a completely different schema.

but this is a basic structural check. we want to make sure the data is as we expect it to be. this means testing the 'data' element in particular. let's see an example of that:

```python
import altair as alt
import json
import unittest
import pandas as pd

class test_altair_data_content(unittest.TestCase):
    def test_data_values_correctly_encoded(self):
      df = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]})
      chart = alt.Chart(df).mark_line().encode(x='x', y='y')

      chart_json = json.loads(chart.to_json())
      actual_data = chart_json['data']['values']

      expected_data = [{'x': 1, 'y': 4}, {'x': 2, 'y': 5}, {'x': 3, 'y': 6}]
      self.assertEqual(actual_data, expected_data)
```
so, here, we check that a specific dataframe generates the data structure we are looking for in the json output. this is quite powerful because it allows us to check how a chart behaves for a specific dataframe. if the transformations performed on the data are wrong and the data passed to the visualization is wrong, this test will fail. this was something that helped us a lot when migrating from one data pipeline to another; we could write tests that would assure that the visualizations generated by both pipelines were actually showing the same data.

now, things get tricky when it comes to more complex encoding parameters like color scales or encodings that have multiple levels. in these cases we have to be much more strict with our test parameters. we can check that specific encoding keys contain the expected values. let's say a specific pipeline has to output a color encoding named `category`. then we can check that. imagine something like this:

```python
import altair as alt
import json
import unittest
import pandas as pd

class TestAltairEncoding(unittest.TestCase):
  def test_color_encoding_exists(self):
    df = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6], 'category': ['A', 'B', 'A']})
    chart = alt.Chart(df).mark_point().encode(
        x='x', y='y', color='category'
    )
    chart_json = json.loads(chart.to_json())

    self.assertIn('encoding', chart_json)
    self.assertIn('color', chart_json['encoding'])
    self.assertEqual(chart_json['encoding']['color']['field'], 'category')
    # additional test to verify that the color scheme has been correctly set
    self.assertEqual(chart_json['encoding']['color']['type'], 'nominal')

```

this test uses the same method of checking the json output. the trick is that now we are drilling down into the `encoding` object and verifying not only that the `color` attribute exists but also that is set up in the way we expect to be. now you can easily check, using the same method, that specific legends have the appropriate title, labels are present, scales are set up in the appropriate way, etc.

when it comes to testing complex visualizations, things can get even more complicated, especially if you are relying heavily on interactive elements or layered charts. in that case i would recommend you do a little more than just the json assertions. you could use a simple html renderer and perform some visual checks. something like selenium might actually be useful in these scenarios. i remember the time where we had to test a series of linked charts that interacted with each other. it was like a mini web application and no simple unit test was going to cut it. we automated a browser and that was how we tested the functionality. it's a bit heavier than just asserting json, but for highly interactive elements, it's sometimes the most practical solution.

one important consideration is that, when doing json assertions, you should never rely on the exact formatting of the json. because it might change. always parse the json before asserting. dont go around trying to match a blob of text with a string. that will just make your tests brittle and annoying. and always be very specific on what you are asserting. you could technically, assert that `len(json_blob) > 1000` but that will be useless if the shape of the data changes and suddenly that check passes with garbage output.

for resources, i'd say checking the vega-lite specification is key. altair translates into vega-lite json, so understanding that spec will allow you to make better assumptions and assertions. something like “the grammar of graphics” by wilkinson is also a great resource to understand how charts work at a fundamental level, that combined with the vega-lite documentation is a powerful combo.

and finally, i would say that while all this is possible, sometimes a manual visual check might be in order. it might sound like cheating but there is a human that has to consume the visualization, and you might be missing some specific thing that only a human eye might catch. after all, if no one can interpret your chart, it doesn’t matter if the tests pass, because it will still be a useless visualization. i learned that the hard way, when we all started going around trying to find the issue in the tests, while all of us were looking at the wrong graph because we had a `category_of_interest` instead of a `target_variable` in our charts, or something like that… (it’s usually something like that actually).
